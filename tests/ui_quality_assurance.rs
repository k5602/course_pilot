//! UI Quality Assurance Test Suite for Course Pilot
//!
//! This module provides comprehensive quality assurance testing that combines
//! performance benchmarks and accessibility compliance testing for UI components.

use dioxus::prelude::*;
use dioxus_ssr::render;
use std::time::{Duration, Instant};
use std::collections::HashMap;

/// Performance benchmark configuration
#[derive(Debug, Clone)]
pub struct BenchmarkConfig {
    pub iterations: usize,
    pub dataset_size: usize,
    pub max_acceptable_time: Duration,
    pub memory_threshold_mb: usize,
}

impl Default for BenchmarkConfig {
    fn default() -> Self {
        Self {
            iterations: 100,
            dataset_size: 1000,
            max_acceptable_time: Duration::from_millis(100),
            memory_threshold_mb: 50,
        }
    }
}

/// Performance metrics collected during benchmarks
#[derive(Debug, Clone)]
pub struct PerformanceMetrics {
    pub min_time: Duration,
    pub max_time: Duration,
    pub avg_time: Duration,
    pub total_time: Duration,
    pub iterations: usize,
    pub memory_usage_mb: f64,
    pub renders_per_second: f64,
}

impl PerformanceMetrics {
    fn new(times: Vec<Duration>, memory_usage_mb: f64) -> Self {
        let total_time: Duration = times.iter().sum();
        let avg_time = total_time / times.len() as u32;
        let min_time = *times.iter().min().unwrap();
        let max_time = *times.iter().max().unwrap();
        let renders_per_second = times.len() as f64 / total_time.as_secs_f64();

        Self {
            min_time,
            max_time,
            avg_time,
            total_time,
            iterations: times.len(),
            memory_usage_mb,
            renders_per_second,
        }
    }
}

/// Accessibility test configuration
#[derive(Debug, Clone)]
pub struct AccessibilityConfig {
    pub check_aria_labels: bool,
    pub check_keyboard_navigation: bool,
    pub check_color_contrast: bool,
    pub check_semantic_html: bool,
    pub check_focus_management: bool,
}

impl Default for AccessibilityConfig {
    fn default() -> Self {
        Self {
            check_aria_labels: true,
            check_keyboard_navigation: true,
            check_color_contrast: true,
            check_semantic_html: true,
            check_focus_management: true,
        }
    }
}

/// Accessibility test results
#[derive(Debug, Clone)]
pub struct AccessibilityResults {
    pub component_name: String,
    pub passed_checks: Vec<String>,
    pub failed_checks: Vec<String>,
    pub warnings: Vec<String>,
    pub score: f32, // 0.0 to 100.0
}

impl AccessibilityResults {
    fn new(component_name: String) -> Self {
        Self {
            component_name,
            passed_checks: Vec::new(),
            failed_checks: Vec::new(),
            warnings: Vec::new(),
            score: 0.0,
        }
    }

    fn add_pass(&mut self, check: &str) {
        self.passed_checks.push(check.to_string());
    }

    fn add_fail(&mut self, check: &str) {
        self.failed_checks.push(check.to_string());
    }

    fn add_warning(&mut self, warning: &str) {
        self.warnings.push(warning.to_string());
    }

    fn calculate_score(&mut self) {
        let total_checks = self.passed_checks.len() + self.failed_checks.len();
        if total_checks > 0 {
            self.score = (self.passed_checks.len() as f32 / total_checks as f32) * 100.0;
        }
    }
}

// Import test functionality directly since we can't use mod in tests
use std::time::{Duration, Instant};
use dioxus::prelude::*;
use dioxus_ssr::render;
use dioxus_core;
use regex::Regex;

// Import components for testing
use course_pilot::ui::components::base::{
    BaseButton, BaseButtonProps, BaseCard, BaseCardProps, BasePage, BasePageProps,
};
use course_pilot::ui::components::{
    ProgressRing, ProgressBar, Toast, Modal,
};

/// Combined quality assurance test configuration
#[derive(Debug, Clone)]
pub struct QualityAssuranceConfig {
    pub performance: BenchmarkConfig,
    pub accessibility: AccessibilityConfig,
    pub min_performance_score: f64, // renders per second
    pub min_accessibility_score: f32, // percentage
    pub max_render_time: Duration,
}

impl Default for QualityAssuranceConfig {
    fn default() -> Self {
        Self {
            performance: BenchmarkConfig::default(),
            accessibility: AccessibilityConfig::default(),
            min_performance_score: 50.0, // 50 renders per second minimum
            min_accessibility_score: 75.0, // 75% accessibility score minimum
            max_render_time: Duration::from_millis(100),
        }
    }
}

/// Combined test results
#[derive(Debug, Clone)]
pub struct QualityAssuranceResults {
    pub component_name: String,
    pub performance_metrics: PerformanceMetrics,
    pub accessibility_results: AccessibilityResults,
    pub overall_score: f32,
    pub passed: bool,
    pub recommendations: Vec<String>,
}

impl QualityAssuranceResults {
    fn new(
        component_name: String,
        performance_metrics: PerformanceMetrics,
        accessibility_results: AccessibilityResults,
        config: &QualityAssuranceConfig,
    ) -> Self {
        let mut recommendations = Vec::new();
        
        // Performance recommendations
        if performance_metrics.renders_per_second < config.min_performance_score {
            recommendations.push(format!(
                "Performance: Improve render speed (current: {:.1} renders/sec, target: {:.1})",
                performance_metrics.renders_per_second,
                config.min_performance_score
            ));
        }
        
        if performance_metrics.avg_time > config.max_render_time {
            recommendations.push(format!(
                "Performance: Reduce average render time (current: {:?}, target: {:?})",
                performance_metrics.avg_time,
                config.max_render_time
            ));
        }
        
        // Accessibility recommendations
        if accessibility_results.score < config.min_accessibility_score {
            recommendations.push(format!(
                "Accessibility: Improve accessibility score (current: {:.1}%, target: {:.1}%)",
                accessibility_results.score,
                config.min_accessibility_score
            ));
        }
        
        for failed_check in &accessibility_results.failed_checks {
            recommendations.push(format!("Accessibility: Fix - {}", failed_check));
        }
        
        // Calculate overall score (weighted average)
        let performance_score = (performance_metrics.renders_per_second / config.min_performance_score * 50.0).min(50.0);
        let accessibility_score = accessibility_results.score / 100.0 * 50.0;
        let overall_score = performance_score + accessibility_score;
        
        let passed = performance_metrics.renders_per_second >= config.min_performance_score
            && accessibility_results.score >= config.min_accessibility_score
            && performance_metrics.avg_time <= config.max_render_time;
        
        Self {
            component_name,
            performance_metrics,
            accessibility_results,
            overall_score,
            passed,
            recommendations,
        }
    }
    
    pub fn print_comprehensive_report(&self) {
        println!("\n{'=':<60}");
        println!("QUALITY ASSURANCE REPORT: {}", self.component_name);
        println!("{'=':<60}");
        
        println!("\nðŸ“Š OVERALL SCORE: {:.1}/100", self.overall_score);
        println!("âœ… STATUS: {}", if self.passed { "PASSED" } else { "NEEDS IMPROVEMENT" });
        
        println!("\nðŸš€ PERFORMANCE METRICS:");
        println!("  â€¢ Average render time: {:?}", self.performance_metrics.avg_time);
        println!("  â€¢ Renders per second: {:.1}", self.performance_metrics.renders_per_second);
        println!("  â€¢ Memory usage: {:.1} MB", self.performance_metrics.memory_usage_mb);
        println!("  â€¢ Min/Max time: {:?} / {:?}", 
                 self.performance_metrics.min_time, 
                 self.performance_metrics.max_time);
        
        println!("\nâ™¿ ACCESSIBILITY METRICS:");
        println!("  â€¢ Accessibility score: {:.1}%", self.accessibility_results.score);
        println!("  â€¢ Passed checks: {}", self.accessibility_results.passed_checks.len());
        println!("  â€¢ Failed checks: {}", self.accessibility_results.failed_checks.len());
        println!("  â€¢ Warnings: {}", self.accessibility_results.warnings.len());
        
        if !self.recommendations.is_empty() {
            println!("\nðŸ’¡ RECOMMENDATIONS:");
            for (i, rec) in self.recommendations.iter().enumerate() {
                println!("  {}. {}", i + 1, rec);
            }
        }
        
        if !self.accessibility_results.failed_checks.is_empty() {
            println!("\nâŒ ACCESSIBILITY ISSUES:");
            for check in &self.accessibility_results.failed_checks {
                println!("  â€¢ {}", check);
            }
        }
        
        if !self.accessibility_results.warnings.is_empty() {
            println!("\nâš ï¸  ACCESSIBILITY WARNINGS:");
            for warning in &self.accessibility_results.warnings {
                println!("  â€¢ {}", warning);
            }
        }
        
        println!("\n{'=':<60}\n");
    }
}

/// Helper function to render a component and measure performance
fn benchmark_component_render<P: Clone + 'static>(
    component: fn(P) -> Element,
    props: P,
    config: &BenchmarkConfig,
) -> PerformanceMetrics {
    let mut render_times = Vec::new();
    
    // Warm up
    for _ in 0..10 {
        let mut dom = VirtualDom::new_with_props(component, props.clone());
        let mut mutations = dioxus_core::Mutations::default();
        let _ = dom.rebuild(&mut mutations);
        let _ = render(&dom);
    }

    // Actual benchmark
    for _ in 0..config.iterations {
        let start = Instant::now();
        
        let mut dom = VirtualDom::new_with_props(component, props.clone());
        let mut mutations = dioxus_core::Mutations::default();
        let _ = dom.rebuild(&mut mutations);
        let _ = render(&dom);
        
        let elapsed = start.elapsed();
        render_times.push(elapsed);
    }

    // Estimate memory usage (simplified)
    let memory_usage_mb = estimate_memory_usage(&render_times);
    
    PerformanceMetrics::new(render_times, memory_usage_mb)
}

/// Simplified memory usage estimation
fn estimate_memory_usage(render_times: &[Duration]) -> f64 {
    let avg_time_ms = render_times.iter().sum::<Duration>().as_millis() as f64 / render_times.len() as f64;
    (avg_time_ms / 10.0).max(1.0)
}

/// Run accessibility test on a component
fn run_accessibility_test<P: Clone + 'static>(
    component: fn(P) -> Element,
    props: P,
    component_name: &str,
    config: &AccessibilityConfig,
) -> AccessibilityResults {
    let html = render_component_for_accessibility(component, props);
    let mut results = AccessibilityResults::new(component_name.to_string());
    
    if config.check_aria_labels {
        check_aria_attributes(&html, &mut results);
    }
    
    if config.check_semantic_html {
        check_semantic_html(&html, &mut results);
    }
    
    if config.check_keyboard_navigation {
        check_keyboard_navigation(&html, &mut results);
    }
    
    if config.check_focus_management {
        check_focus_management(&html, &mut results);
    }
    
    if config.check_color_contrast {
        check_color_contrast(&html, &mut results);
    }
    
    results.calculate_score();
    results
}

/// Helper function to render component and get HTML for accessibility testing
fn render_component_for_accessibility<P: Clone + 'static>(
    component: fn(P) -> Element,
    props: P,
) -> String {
    let mut dom = VirtualDom::new_with_props(component, props);
    let mut mutations = dioxus_core::Mutations::default();
    let _ = dom.rebuild(&mut mutations);
    render(&dom)
}

/// Check if HTML contains proper ARIA labels and attributes
fn check_aria_attributes(html: &str, results: &mut AccessibilityResults) {
    if html.contains("aria-label=") {
        results.add_pass("Contains aria-label attributes");
    } else {
        results.add_warning("No aria-label attributes found - may be acceptable if using other labeling methods");
    }
    
    if html.contains("aria-describedby=") {
        results.add_pass("Contains aria-describedby attributes");
    }
    
    if html.contains("aria-expanded=") {
        results.add_pass("Contains aria-expanded attributes for interactive elements");
    }
    
    if html.contains("aria-hidden=\"true\"") {
        results.add_warning("Contains aria-hidden=\"true\" - ensure decorative elements only");
    }
    
    if html.contains("role=") {
        results.add_pass("Contains role attributes for semantic clarity");
    }
    
    if html.contains("aria-live=") {
        results.add_pass("Contains aria-live regions for dynamic content");
    }
}

/// Check for proper semantic HTML structure
fn check_semantic_html(html: &str, results: &mut AccessibilityResults) {
    let h1_count = html.matches("<h1").count();
    let h2_count = html.matches("<h2").count();
    let h3_count = html.matches("<h3").count();
    
    if h1_count <= 1 {
        results.add_pass("Proper h1 usage (0 or 1 h1 elements)");
    } else {
        results.add_fail("Multiple h1 elements found - should have only one per page");
    }
    
    if h2_count > 0 || h3_count > 0 {
        results.add_pass("Uses proper heading hierarchy");
    }
    
    let semantic_elements = ["nav", "main", "section", "article", "aside", "header", "footer"];
    let mut found_semantic = false;
    
    for element in &semantic_elements {
        if html.contains(&format!("<{}", element)) {
            found_semantic = true;
            break;
        }
    }
    
    if found_semantic {
        results.add_pass("Uses semantic HTML elements");
    } else {
        results.add_warning("No semantic HTML elements found - consider using nav, main, section, etc.");
    }
    
    if html.contains("<button") {
        results.add_pass("Uses proper button elements");
    }
    
    if html.contains("<input") || html.contains("<textarea") || html.contains("<select") {
        if html.contains("id=") && html.contains("for=") {
            results.add_pass("Form elements have proper label associations");
        } else {
            results.add_warning("Form elements may lack proper label associations");
        }
    }
}

/// Check for keyboard navigation support
fn check_keyboard_navigation(html: &str, results: &mut AccessibilityResults) {
    if html.contains("tabindex=") {
        if html.contains("tabindex=\"-1\"") {
            results.add_pass("Uses tabindex=\"-1\" for programmatic focus management");
        }
        if html.contains("tabindex=\"0\"") {
            results.add_pass("Uses tabindex=\"0\" for keyboard accessibility");
        }
        if Regex::new(r#"tabindex="[1-9]""#).unwrap().is_match(html) {
            results.add_fail("Uses positive tabindex values - this can break natural tab order");
        }
    }
    
    let interactive_elements = ["button", "input", "textarea", "select", "a"];
    let mut has_interactive = false;
    
    for element in &interactive_elements {
        if html.contains(&format!("<{}", element)) {
            has_interactive = true;
            break;
        }
    }
    
    if has_interactive {
        results.add_pass("Contains keyboard-accessible interactive elements");
    }
    
    if html.contains("<a") {
        if html.contains("href=") {
            results.add_pass("Links have proper href attributes");
        } else {
            results.add_fail("Links without href attributes are not keyboard accessible");
        }
    }
}

/// Check for focus management
fn check_focus_management(html: &str, results: &mut AccessibilityResults) {
    let focus_indicators = ["focus:", "focus-visible:", "focus-within:"];
    let mut has_focus_styling = false;
    
    for indicator in &focus_indicators {
        if html.contains(indicator) {
            has_focus_styling = true;
            break;
        }
    }
    
    if has_focus_styling {
        results.add_pass("Includes focus styling indicators");
    } else {
        results.add_warning("No focus styling indicators found - ensure focus is visible");
    }
    
    if html.contains("skip") && html.contains("main") {
        results.add_pass("Contains skip navigation links");
    }
}

/// Check for color contrast and visual accessibility
fn check_color_contrast(html: &str, results: &mut AccessibilityResults) {
    let good_contrast_classes = [
        "text-base-content", "text-primary-content", "text-secondary-content",
        "text-accent-content", "text-neutral-content", "text-info-content",
        "text-success-content", "text-warning-content", "text-error-content"
    ];
    
    let mut has_contrast_classes = false;
    for class in &good_contrast_classes {
        if html.contains(class) {
            has_contrast_classes = true;
            break;
        }
    }
    
    if has_contrast_classes {
        results.add_pass("Uses DaisyUI contrast-safe color classes");
    }
    
    let potential_issues = ["text-gray-400", "text-gray-300", "opacity-50"];
    for issue in &potential_issues {
        if html.contains(issue) {
            results.add_warning(&format!("Contains {} which may have contrast issues", issue));
        }
    }
    
    if html.contains("color:") && !html.contains("aria-label") {
        results.add_warning("Uses color styling - ensure information is not conveyed by color alone");
    }
}

/// Run comprehensive quality assurance test on a component
fn run_comprehensive_qa_test<P: Clone + 'static>(
    component: fn(P) -> Element,
    props: P,
    component_name: &str,
    config: &QualityAssuranceConfig,
) -> QualityAssuranceResults {
    println!("Running comprehensive QA test for {}...", component_name);
    
    // Run performance benchmark
    let performance_metrics = benchmark_component_render(
        component,
        props.clone(),
        &config.performance,
    );
    
    // Run accessibility test
    let accessibility_results = run_accessibility_test(
        component,
        props,
        component_name,
        &config.accessibility,
    );
    
    QualityAssuranceResults::new(
        component_name.to_string(),
        performance_metrics,
        accessibility_results,
        config,
    )
}

#[cfg(test)]
mod quality_assurance_tests {
    use super::*;

    #[test]
    fn test_base_button_comprehensive_qa() {
        let config = QualityAssuranceConfig::default();
        
        let results = run_comprehensive_qa_test(
            BaseButton,
            BaseButtonProps {
                children: rsx! { "QA Test Button" },
                onclick: None,
                color: Some("primary".to_string()),
                size: Some("md".to_string()),
                variant: None,
                class: "",
                disabled: false,
                icon: Some(rsx! { span { "ðŸ”" } }),
                loading: false,
                button_type: "button",
            },
            "BaseButton",
            &config,
        );

        results.print_comprehensive_report();
        
        // Comprehensive assertions
        assert!(
            results.passed,
            "BaseButton failed comprehensive QA test. Recommendations: {:?}",
            results.recommendations
        );
        
        assert!(
            results.overall_score >= 75.0,
            "BaseButton overall QA score ({:.1}) is below acceptable threshold (75.0)",
            results.overall_score
        );
    }

    #[test]
    fn test_base_card_comprehensive_qa() {
        let config = QualityAssuranceConfig::default();
        
        let results = run_comprehensive_qa_test(
            BaseCard,
            BaseCardProps {
                title: Some("QA Test Card".to_string()),
                subtitle: Some("Comprehensive quality assurance testing".to_string()),
                children: rsx! {
                    div { class: "space-y-4",
                        p { "This card is being tested for both performance and accessibility." }
                        div { class: "stats shadow",
                            div { class: "stat",
                                div { class: "stat-title", "Performance" }
                                div { class: "stat-value text-primary", "Fast" }
                            }
                            div { class: "stat",
                                div { class: "stat-title", "Accessibility" }
                                div { class: "stat-value text-success", "A11y" }
                            }
                        }
                        div { class: "alert alert-info",
                            span { "Quality assurance testing in progress..." }
                        }
                    }
                },
                variant: "card",
                class: "w-96",
                hover_effect: true,
                on_click: None,
                actions: Some(rsx! {
                    button { 
                        class: "btn btn-primary",
                        r#type: "button",
                        "aria-label": "Primary action for QA test card",
                        "Primary"
                    }
                    button { 
                        class: "btn btn-secondary",
                        r#type: "button",
                        "aria-label": "Secondary action for QA test card",
                        "Secondary"
                    }
                }),
                header_actions: Some(rsx! {
                    button { 
                        class: "btn btn-ghost btn-sm",
                        r#type: "button",
                        "aria-label": "More options for QA test card",
                        "â‹®"
                    }
                }),
            },
            "BaseCard",
            &config,
        );

        results.print_comprehensive_report();
        
        // Comprehensive assertions
        assert!(
            results.passed,
            "BaseCard failed comprehensive QA test. Recommendations: {:?}",
            results.recommendations
        );
        
        assert!(
            results.overall_score >= 70.0,
            "BaseCard overall QA score ({:.1}) is below acceptable threshold (70.0)",
            results.overall_score
        );
    }

    #[test]
    fn test_progress_components_comprehensive_qa() {
        let config = QualityAssuranceConfig {
            min_performance_score: 100.0, // Higher standard for simple components
            min_accessibility_score: 70.0,
            ..Default::default()
        };
        
        // Test ProgressRing
        let ring_results = run_comprehensive_qa_test(
            ProgressRing,
            course_pilot::ui::components::progress::ProgressRingProps {
                value: 75,
                max: Some(100),
                color: Some("primary".to_string()),
                size: Some(48),
                thickness: Some(4),
                label: Some(rsx! { 
                    span { 
                        class: "sr-only",
                        "Progress: 75 percent complete"
                    }
                }),
            },
            "ProgressRing",
            &config,
        );

        ring_results.print_comprehensive_report();
        
        // Test ProgressBar
        let bar_results = run_comprehensive_qa_test(
            ProgressBar,
            course_pilot::ui::components::progress::ProgressBarProps {
                value: 60,
                label: Some("Upload progress".to_string()),
                color: Some("success".to_string()),
                class: Some("w-full".to_string()),
            },
            "ProgressBar",
            &config,
        );

        bar_results.print_comprehensive_report();
        
        // Progress components should have high performance and accessibility
        assert!(
            ring_results.passed,
            "ProgressRing failed QA test: {:?}",
            ring_results.recommendations
        );
        
        assert!(
            bar_results.passed,
            "ProgressBar failed QA test: {:?}",
            bar_results.recommendations
        );
        
        assert!(
            ring_results.overall_score >= 80.0,
            "ProgressRing QA score too low: {:.1}",
            ring_results.overall_score
        );
        
        assert!(
            bar_results.overall_score >= 80.0,
            "ProgressBar QA score too low: {:.1}",
            bar_results.overall_score
        );
    }

    #[test]
    fn test_large_dataset_comprehensive_qa() {
        let config = QualityAssuranceConfig {
            performance: BenchmarkConfig {
                iterations: 5, // Fewer iterations for large dataset
                dataset_size: 50,
                max_acceptable_time: Duration::from_millis(300),
                memory_threshold_mb: 100,
            },
            min_performance_score: 20.0, // Lower expectation for large datasets
            min_accessibility_score: 80.0, // Higher accessibility standard
            max_render_time: Duration::from_millis(300),
        };
        
        // Generate test data
        let courses: Vec<_> = (0..config.performance.dataset_size).map(|i| {
            (
                format!("Course {}", i),
                format!("Description for course {} with detailed information", i),
                (i * 2) % 100,
            )
        }).collect();
        
        let results = run_comprehensive_qa_test(
            BasePage,
            BasePageProps {
                title: Some("Large Dataset QA Test".to_string()),
                subtitle: Some(format!("Testing {} items", courses.len())),
                children: rsx! {
                    main {
                        section { class: "grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4",
                            {courses.iter().enumerate().map(|(i, (title, desc, progress))| {
                                rsx! {
                                    article { key: "{i}",
                                        class: "card bg-base-100 shadow-xl",
                                        div { class: "card-body",
                                            h3 { class: "card-title", "{title}" }
                                            p { class: "text-sm text-base-content/70", "{desc}" }
                                            div { class: "card-actions justify-between items-center mt-4",
                                                div { class: "radial-progress text-primary text-sm",
                                                    style: "--value:{progress}; --size:2rem;",
                                                    "aria-label": "Progress: {progress} percent",
                                                    "{progress}%"
                                                }
                                                button { 
                                                    class: "btn btn-primary btn-sm",
                                                    r#type: "button",
                                                    "aria-label": "View {title}",
                                                    "View"
                                                }
                                            }
                                        }
                                    }
                                }
                            })}
                        }
                    }
                },
                header_actions: Some(rsx! {
                    nav {
                        button { 
                            class: "btn btn-primary",
                            r#type: "button",
                            "Add Course"
                        }
                        button { 
                            class: "btn btn-secondary",
                            r#type: "button",
                            "Import"
                        }
                    }
                }),
                breadcrumbs: Some(rsx! {
                    nav { 
                        class: "breadcrumbs",
                        "aria-label": "Breadcrumb navigation",
                        ul {
                            li { a { href: "/", "Home" } }
                            li { a { href: "/courses", "Courses" } }
                            li { "QA Test" }
                        }
                    }
                }),
                class: "",
                max_width: "max-w-7xl",
                padded: true,
                background: "bg-base-100",
            },
            "Large Dataset",
            &config,
        );

        results.print_comprehensive_report();
        
        // Large dataset specific assertions
        assert!(
            results.performance_metrics.avg_time < config.max_render_time,
            "Large dataset render time ({:?}) exceeds threshold ({:?})",
            results.performance_metrics.avg_time,
            config.max_render_time
        );
        
        assert!(
            results.accessibility_results.score >= config.min_accessibility_score,
            "Large dataset accessibility score ({:.1}%) below threshold ({:.1}%)",
            results.accessibility_results.score,
            config.min_accessibility_score
        );
        
        // Should have proper semantic structure for large datasets
        assert!(
            results.accessibility_results.passed_checks.iter()
                .any(|check| check.contains("semantic HTML")),
            "Large dataset should use proper semantic HTML structure"
        );
    }

    #[test]
    fn test_component_stress_testing() {
        // Stress test with extreme conditions
        let stress_config = QualityAssuranceConfig {
            performance: BenchmarkConfig {
                iterations: 200, // High iteration count
                dataset_size: 10,
                max_acceptable_time: Duration::from_millis(50), // Strict timing
                memory_threshold_mb: 25, // Low memory threshold
            },
            min_performance_score: 150.0, // High performance requirement
            min_accessibility_score: 85.0, // High accessibility requirement
            max_render_time: Duration::from_millis(50),
        };
        
        let results = run_comprehensive_qa_test(
            BaseButton,
            BaseButtonProps {
                children: rsx! { "Stress Test" },
                onclick: None,
                color: Some("primary".to_string()),
                size: Some("md".to_string()),
                variant: Some("outline".to_string()),
                class: "btn-wide",
                disabled: false,
                icon: Some(rsx! { span { "âš¡" } }),
                loading: false,
                button_type: "button",
            },
            "BaseButton (Stress Test)",
            &stress_config,
        );

        results.print_comprehensive_report();
        
        // Stress test should still maintain reasonable performance
        assert!(
            results.performance_metrics.avg_time < Duration::from_millis(100),
            "Component failed stress test - render time too slow: {:?}",
            results.performance_metrics.avg_time
        );
        
        assert!(
            results.accessibility_results.score >= 75.0,
            "Component failed stress test - accessibility score too low: {:.1}%",
            results.accessibility_results.score
        );
        
        // Memory usage should remain reasonable under stress
        assert!(
            results.performance_metrics.memory_usage_mb < 50.0,
            "Component failed stress test - memory usage too high: {:.1} MB",
            results.performance_metrics.memory_usage_mb
        );
    }
}

/// Generate comprehensive QA report for all components
#[allow(dead_code)]
pub fn generate_comprehensive_qa_report() {
    println!("Generating Comprehensive Quality Assurance Report for Course Pilot UI Components");
    println!("================================================================================\n");
    
    let config = QualityAssuranceConfig::default();
    let mut all_results = Vec::new();
    
    // This would test all components and generate a comprehensive report
    // In practice, individual tests are run via `cargo test`
    
    println!("QA Report generation completed. Run individual tests with:");
    println!("cargo test test_base_button_comprehensive_qa -- --nocapture");
    println!("cargo test test_base_card_comprehensive_qa -- --nocapture");
    println!("cargo test test_progress_components_comprehensive_qa -- --nocapture");
    println!("cargo test test_large_dataset_comprehensive_qa -- --nocapture");
    println!("cargo test test_component_stress_testing -- --nocapture");
}